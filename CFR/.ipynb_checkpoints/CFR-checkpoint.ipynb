{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.558382638266356e-09, 9.380665758621118e-10, 1.788246457104589e-08, 0.9999629971678955, 0.9999999999999987]\n",
      "[6.423819761215262e-10, 7.677924283248825e-10, 2.009370106425513e-08, 0.9998774774996924, 0.9999999999999987]\n"
     ]
    }
   ],
   "source": [
    "from copy import copy as cp\n",
    "from random import shuffle as shfl\n",
    "import random\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "def get_new_prob(old_prob,value):\n",
    "    return old_prob + 0.02*value*(old_prob)*(1-old_prob)\n",
    "# def get_new_prob(old_prob):\n",
    "#     return old_prob + 0.02*value*(old_prob)*(1-old_prob)\n",
    "\n",
    "def get_act(call_prob):\n",
    "    rnd = random.random()\n",
    "    if call_prob>rnd:\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'f'\n",
    "\n",
    "a_c = [0.5]*5\n",
    "b_c = [0.5]*5\n",
    "\n",
    "crd = [0,1,2,3,4]\n",
    "for i in range(10000):\n",
    "    shfl(crd)\n",
    "    p1_act = get_act(a_c[crd[0]])\n",
    "    p2_act = get_act(b_c[crd[1]])\n",
    "\n",
    "    if p1_act == 'c':\n",
    "        if p2_act=='c':\n",
    "            if crd[0]>crd[1]:\n",
    "                a_c[crd[0]] = get_new_prob(a_c[crd[0]],2)\n",
    "                b_c[crd[1]] = get_new_prob(b_c[crd[1]],-2)\n",
    "            else:\n",
    "                a_c[crd[0]] = get_new_prob(a_c[crd[0]],-2)\n",
    "                b_c[crd[1]] = get_new_prob(b_c[crd[1]],2)\n",
    "        else:\n",
    "                a_c[crd[0]] = get_new_prob(a_c[crd[0]],1)\n",
    "                b_c[crd[1]] = get_new_prob(b_c[crd[1]],-1)\n",
    "\n",
    "    else:\n",
    "        if p2_act=='c':\n",
    "                a_c[crd[0]] = get_new_prob(a_c[crd[0]],-1)\n",
    "                b_c[crd[1]] = get_new_prob(b_c[crd[1]],1) \n",
    "\n",
    "\n",
    "print(a_c)\n",
    "print(b_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0046\n"
     ]
    }
   ],
   "source": [
    "# real game\n",
    "a_c = [0 ,0 ,0.5,1,1]\n",
    "b_c = [0,0,1,1,1]\n",
    "a=0\n",
    "game = 100000\n",
    "for i in range(game):\n",
    "    shfl(crd)\n",
    "    a_act = get_act(a_c[crd[0]])\n",
    "    b_act = get_act(b_c[crd[1]])\n",
    "\n",
    "    if a_act == 'c':\n",
    "        if b_act=='c':\n",
    "            if crd[0]>crd[1]:\n",
    "                a+=2\n",
    "            else:\n",
    "                a-=2\n",
    "        else:\n",
    "                a+=1\n",
    "\n",
    "    else:\n",
    "        if b_act=='c':\n",
    "                a-=1\n",
    "print(a/game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000000000000002\n",
      "-0.17\n"
     ]
    }
   ],
   "source": [
    "# EV\n",
    "# a_c = [0,0,0.65,1,1]\n",
    "# b_c = [0,0,1,1,1]\n",
    "def get_EV(a_c,b_c):\n",
    "    a_EV = 0\n",
    "    for i in range(5):\n",
    "        for j in range(i+1,5):\n",
    "            a_EV += a_c[i]*b_c[j]*(-2)\n",
    "            a_EV += a_c[j]*b_c[i]*2 \n",
    "            a_EV+= -(1-a_c[i])*b_c[j]+a_c[i]*(1-b_c[j])\n",
    "            a_EV+= -(1-a_c[j])*b_c[i]+a_c[j]*(1-b_c[i])\n",
    "\n",
    "    return  a_EV/20  #P(5,2) possible game state\n",
    "#Test Unit\n",
    "# print(get_EV([0,0,0,0,0],[1,1,1,1,1])) #-1\n",
    "# print(get_EV([1,1,1,1,1],[0,0,0,0,0])) #1\n",
    "# print(get_EV([0,1,1,1,1],[1,1,1,1,1])) #0\n",
    "print(get_EV([1.0, 1.0, 1.0, 1.0, 1.0],[1.0, 0.7, 0, 0.0, 1])) #0\n",
    "\n",
    "print(get_EV([0.9, 0.8, 0.6, 1, 1 ],[0,0,1,1,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bisection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[0, 0.0, 1.0, 1.0, 1.0]\n",
      "[0.0, 0.0, 0.90000000000000002, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "p1_c = [0,0,0,0,0]\n",
    "p2_c = [1,1,1,1,1]\n",
    "idx = 0\n",
    "max_util = 0\n",
    "for it in range(1010):\n",
    "    trainer = it%2\n",
    "    if trainer == 0:\n",
    "        trainer = p1_c\n",
    "        whose_EV = 1\n",
    "    else:\n",
    "        trainer = p2_c\n",
    "        whose_EV = -1\n",
    "    for idx in range(5):\n",
    "        #sweep\n",
    "        old_ratio = trainer[idx] \n",
    "        max_util =  whose_EV*get_EV(p1_c,p2_c)\n",
    "        rec_r = -1\n",
    "        for r in np.arange(0,1.1,0.1):\n",
    "            trainer[idx] = r\n",
    "            util =  whose_EV*get_EV(p1_c,p2_c)\n",
    "            if max_util<util:\n",
    "                rec_r = r\n",
    "        if rec_r != -1:\n",
    "            trainer[idx] =rec_r\n",
    "        else:\n",
    "            trainer[idx] =old_ratio\n",
    "    if get_EV(p1_c,p2_c)==0:\n",
    "        print(it)\n",
    "        break\n",
    "    if  1000<it<1010:\n",
    "        print(it%2)\n",
    "        print(p1_c)\n",
    "        print(p2_c)\n",
    "print(p1_c)\n",
    "print(p2_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for r in np.arange(0,1.1,0.1):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(get_EV([0,0,1,1,1],[0,0,0,1,1]))\n",
    "for i in np.arange(0,1.1,0.1):\n",
    "    print(get_EV([0,0,i,1,1],[0,0,0,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def modi(x):\n",
    "    x+=1\n",
    "class A():\n",
    "    def __init__(self):\n",
    "        self.c=[1]*5\n",
    "a = A()\n",
    "modi(a.c[0])\n",
    "print(a.c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008 ,0.095 ,0.329 ,0.539 ,0.994 ,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from copy import copy as cp\n",
    "from random import shuffle as shfl\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_act(call_prob):\n",
    "    rnd = random.random()\n",
    "    if call_prob>rnd:\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'f'\n",
    "class Ply():\n",
    "    def __init__(self):\n",
    "        self.c=[1]*5\n",
    "        self.f=[1]*5\n",
    "    def get_call_prob(self,crd):\n",
    "        return self.c[crd]/(self.c[crd]+self.f[crd])\n",
    "    def p_prob(self):\n",
    "        for i in range(5):\n",
    "            print(round(self.get_call_prob(i),3),',', end=\"\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "p1 = Ply()\n",
    "p2 = Ply()\n",
    "crd = [0,1,2,3,4]\n",
    "p2.c =np.array([0.007 ,0.109 ,0.341 ,0.54 ,0.994])\n",
    "p2.f =1 - p2.c\n",
    "\n",
    "for i in range(100000):\n",
    "    shfl(crd)\n",
    "    p1_act = get_act(p1.get_call_prob(crd[0]))\n",
    "    p2_act = get_act(p2.get_call_prob(crd[1]))\n",
    "\n",
    "    if p1_act == 'c':\n",
    "        if p2_act=='c':\n",
    "            if crd[0]<crd[1]:\n",
    "#                 p2.f[crd[1]]+=1\n",
    "#             else:\n",
    "                p1.f[crd[0]]+=1\n",
    "#         else:\n",
    "#             if crd[0]<crd[1]:\n",
    "#                 p2.c[crd[1]]+=3\n",
    "\n",
    "    else:\n",
    "        if p2_act=='c':\n",
    "            if crd[0]>crd[1]:\n",
    "                p1.c[crd[0]]+=3\n",
    "\n",
    "                \n",
    "p1.p_prob()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Use simple regret-matching strategy === \n",
      "{Alasdair: 3291, Calum: 3215, 'Draw': 3494}\n",
      "==== Use averaged regret-matching strategy === \n",
      "{Alasdair: 3325, Calum: 3316, 'Draw': 3359}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "    Use regret-matching algorithm to play Scissors-Rock-Paper.\n",
    "'''\n",
    "\n",
    "class RPS:\n",
    "    actions = ['ROCK', 'PAPER', 'SCISSORS']\n",
    "    n_actions = 3\n",
    "    utilities = pd.DataFrame([\n",
    "        # ROCK  PAPER  SCISSORS\n",
    "        [ 0,    -1,    1], # ROCK\n",
    "        [ 1,     0,   -1], # PAPER\n",
    "        [-1,     1,    0]  # SCISSORS\n",
    "    ], columns=actions, index=actions)\n",
    "\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, name):\n",
    "        self.strategy, self.avg_strategy,\\\n",
    "        self.strategy_sum, self.regret_sum = np.zeros((4, RPS.n_actions))\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "\n",
    "    def update_strategy(self):\n",
    "        \"\"\"\n",
    "        set the preference (strategy) of choosing an action to be proportional to positive regrets\n",
    "        e.g, a strategy that prefers PAPER can be [0.2, 0.6, 0.2]\n",
    "        \"\"\"\n",
    "        self.strategy = np.copy(self.regret_sum)\n",
    "        self.strategy[self.strategy < 0] = 0  # reset negative regrets to zero\n",
    "\n",
    "        summation = sum(self.strategy)\n",
    "        if summation > 0:\n",
    "            # normalise\n",
    "            self.strategy /= summation\n",
    "        else:\n",
    "            # uniform distribution to reduce exploitability\n",
    "            self.strategy = np.repeat(1 / RPS.n_actions, RPS.n_actions)\n",
    "\n",
    "        self.strategy_sum += self.strategy\n",
    "\n",
    "    def regret(self, my_action, opp_action):\n",
    "        \"\"\"\n",
    "        we here define the regret of not having chosen an action as the difference between the utility of that action\n",
    "        and the utility of the action we actually chose, with respect to the fixed choices of the other player.\n",
    "\n",
    "        compute the regret and add it to regret sum.\n",
    "        \"\"\"\n",
    "        result = RPS.utilities.loc[my_action, opp_action]\n",
    "        facts = RPS.utilities.loc[:, opp_action].values\n",
    "        regret = facts - result\n",
    "        self.regret_sum += regret\n",
    "\n",
    "    def action(self, use_avg=False):\n",
    "        \"\"\"\n",
    "        select an action according to strategy probabilities\n",
    "        \"\"\"\n",
    "        strategy = self.avg_strategy if use_avg else self.strategy\n",
    "        return np.random.choice(RPS.actions, p=strategy)\n",
    "\n",
    "    def learn_avg_strategy(self):\n",
    "        # averaged strategy converges to Nash Equilibrium\n",
    "        summation = sum(self.strategy_sum)\n",
    "        if summation > 0:\n",
    "            self.avg_strategy = self.strategy_sum / summation\n",
    "        else:\n",
    "            self.avg_strategy = np.repeat(1/RPS.n_actions, RPS.n_actions)\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, max_game=10000):\n",
    "        self.p1 = Player('Alasdair')\n",
    "        self.p2 = Player('Calum')\n",
    "        self.max_game = max_game\n",
    "\n",
    "    def winner(self, a1, a2):\n",
    "        result = RPS.utilities.loc[a1, a2]\n",
    "        if result == 1:     return self.p1\n",
    "        elif result == -1:  return self.p2\n",
    "        else:               return 'Draw'\n",
    "\n",
    "    def play(self, avg_regret_matching=False):\n",
    "        def play_regret_matching():\n",
    "            for i in range(0, self.max_game):\n",
    "                self.p1.update_strategy()\n",
    "                self.p2.update_strategy()\n",
    "                a1 = self.p1.action()\n",
    "                a2 = self.p2.action()\n",
    "                self.p1.regret(a1, a2)\n",
    "                self.p2.regret(a2, a1)\n",
    "\n",
    "                winner = self.winner(a1, a2)\n",
    "                num_wins[winner] += 1\n",
    "\n",
    "        def play_avg_regret_matching():\n",
    "            for i in range(0, self.max_game):\n",
    "                a1 = self.p1.action(use_avg=True)\n",
    "                a2 = self.p2.action(use_avg=True)\n",
    "                winner = self.winner(a1, a2)\n",
    "                num_wins[winner] += 1\n",
    "\n",
    "        num_wins = {\n",
    "            self.p1: 0,\n",
    "            self.p2: 0,\n",
    "            'Draw': 0\n",
    "        }\n",
    "\n",
    "        play_regret_matching() if not avg_regret_matching else play_avg_regret_matching()\n",
    "        print(num_wins)\n",
    "\n",
    "    def conclude(self):\n",
    "        \"\"\"\n",
    "        let two players conclude the average strategy from the previous strategy stats \n",
    "        \"\"\"\n",
    "        self.p1.learn_avg_strategy()\n",
    "        self.p2.learn_avg_strategy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    game = Game()\n",
    "\n",
    "    print('==== Use simple regret-matching strategy === ')\n",
    "    game.play()\n",
    "    print('==== Use averaged regret-matching strategy === ')\n",
    "    game.conclude()\n",
    "    game.play(avg_regret_matching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
